{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WksDx4_To_su"
      },
      "source": [
        "# PYTTI: Python Text-to-Image \n",
        "\n",
        "AI-Assisted Artistic Image Generation and Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZt160ePEc8f"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "Setup instructions can be found here: https://github.com/pytti-tools/pytti-notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcayyBJjE-qy"
      },
      "source": [
        "# 2: Define Parameters (i.e. the inputs to this tool)\n",
        "\n",
        "Please modify the values in the `config/` folder's yaml files, the files will be read when you execute the main \"workhorse\" cell.\n",
        "\n",
        "Feel free to modify the values in `config/default.yaml`. If you have discovered alternative default settings that you prefer, feel free to persist them in that file. You can then specify your runs by authoring files that define just the parameters you want to change in the `config/conf/` folder. An example `demo.yaml` is provided. \n",
        "\n",
        "In the following cell, we specify the name of the config file containing the overrides to the default settings. To use override settings other than those contained in `config/conf/demo.yaml`, specify the correct filename below. \n",
        "\n",
        "Descriptions of parameter options and features can be found at the bottom of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If multiple filenames are present, they will be looped\n",
        "CONFIG_OVERRIDES = [] # [\"demo.yaml\"] # File(s) located in config/conf\n",
        "\n",
        "# You probably don't need to touch these\n",
        "CONFIG_BASE_PATH = \"config\"\n",
        "CONFIG_DEFAULTS = \"default.yaml\"\n",
        "\n",
        "# If randomize_seed is set to False, two runs with the same parameters will produce the same outputs\n",
        "#RANDOMIZE_SEED = False # feature not yet supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# overrides to let you paste raw json\n",
        "null=None\n",
        "true=True\n",
        "false=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you would like to use parameters generated by pyttipanna or an older version of the notebook, incorporate them below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Replace '{}' with your pytti panna thing\n",
        "pytti_panna_output = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. (Optional) Monitor Outputs with Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook supports tensorboard outputs. These are the same values that will be printed while the notebook runs, but they may be easier to navigate in tensorboard if you want to start a server. Uncomment the cell below to initialize tensorboard in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from pytti.workhorse import _main, TB_LOGDIR \n",
        "\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir $TB_LOGDIR "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. RUN IT!\n",
        "\n",
        "Just execute the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
        "from loguru import logger\n",
        "from omegaconf import OmegaConf\n",
        "from pytti.workhorse import _main as render_frames\n",
        "\n",
        "try:\n",
        "    assert isinstance(CONFIG_OVERRIDES, list)\n",
        "except AssertionError:\n",
        "    if isinstance(CONFIG_OVERRIDES, str):\n",
        "        logger.warning(\n",
        "            \"The CONFIG_OVERRIDES variable should be a list of filenames.\"\n",
        "            \"I noticed you set this variable to a string. I'll wrap that in \"\n",
        "            \"a list for you this time, but after this cell completes execution, \"\n",
        "            \"please repair how you set the variable above. Instead of\"\n",
        "            f'\\n\\n\\tCONFIG_OVERRIDES=\"{CONFIG_OVERRIDES}\\n\\n'\n",
        "            \"it should be\"\n",
        "            f'\\n\\n\\tCONFIG_OVERRIDES=[\"{CONFIG_OVERRIDES}\"]\\n\\n'\n",
        "        )\n",
        "        CONFIG_OVERRIDES = [CONFIG_OVERRIDES]\n",
        "\n",
        "# https://github.com/facebookresearch/hydra/blob/main/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n",
        "# https://omegaconf.readthedocs.io/\n",
        "# https://hydra.cc/docs/intro/\n",
        "with initialize(config_path=CONFIG_BASE_PATH):\n",
        "    if pytti_panna_output:\n",
        "        cfg = OmegaConf.create(pytti_panna_output)\n",
        "        render_frames(cfg)\n",
        "    for c_o in CONFIG_OVERRIDES:\n",
        "        cfg = compose(config_name=CONFIG_DEFAULTS, \n",
        "                      overrides=[f\"conf={c_o}\"])\n",
        "        #print(cfg)\n",
        "        render_frames(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtekvTZxFNpf"
      },
      "source": [
        "# 4. Render video\n",
        "\n",
        "The first run executed in `file_namespace` (probably set to `default`) is number $0$, the second is number $1$, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RZH-r4yyShnX"
      },
      "outputs": [],
      "source": [
        "#@title 3.1 Render video\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from os.path import exists as path_exists\n",
        "from subprocess import Popen, PIPE\n",
        "from PIL import Image, ImageFile\n",
        "from os.path import splitext as split_file\n",
        "import glob\n",
        "from pytti.Notebook import get_last_file\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  raise RuntimeError(\"ERROR: no parameters. Please run parameters (step 2.1).\")\n",
        "\n",
        "if not path_exists(f\"images_out/{params.file_namespace}\"):\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"ERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "\n",
        "#@markdown The first run executed in `file_namespace` is number $0$, the second is number $1$, etc.\n",
        "\n",
        "latest = -1\n",
        "run_number = latest#@param{type:\"raw\"}\n",
        "if run_number == -1:\n",
        "  _, i = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "  run_number = i\n",
        "base_name = params.file_namespace if run_number == 0 else (params.file_namespace+f\"({run_number})\")\n",
        "tqdm.write(f'Generating video from {params.file_namespace}/{base_name}_*.png')\n",
        "\n",
        "all_frames = glob.glob(f'images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "all_frames.sort(key = lambda s: int(split_file(s)[0].split('_')[-1]))\n",
        "print(f'found {len(all_frames)} frames matching images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "\n",
        "start_frame = 0#@param{type:\"number\"}\n",
        "all_frames = all_frames[start_frame:]\n",
        "\n",
        "fps =  params.frames_per_second#@param{type:\"raw\"}\n",
        "\n",
        "total_frames = len(all_frames)\n",
        "\n",
        "if total_frames == 0:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(f\"ERROR: no frames to render in images_out/{params.file_namespace}\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for filename in tqdm(all_frames):\n",
        "  frames.append(Image.open(filename))\n",
        "\n",
        "p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', f\"videos/{base_name}.mp4\"], stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "  im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "print(\"Video complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t3EgqHKrSjZx"
      },
      "outputs": [],
      "source": [
        "#@title 3.1 Render video (concatenate all runs)\n",
        "from os.path import exists as path_exists\n",
        "if path_exists('/content/drive/MyDrive/pytti_test'):\n",
        "  %cd /content/drive/MyDrive/pytti_test\n",
        "  drive_mounted = True\n",
        "else:\n",
        "  drive_mounted = False\n",
        "try:\n",
        "  from pytti.Notebook import change_tqdm_color\n",
        "except ModuleNotFoundError:\n",
        "  if drive_mounted:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('ERROR: please run setup (step 1.3).')\n",
        "  else:\n",
        "    #THIS IS NOT AN ERROR. This is the code that would\n",
        "    #make an error if something were wrong.\n",
        "    raise RuntimeError('WARNING: drive is not mounted.\\nERROR: please run setup (step 1.3).')\n",
        "change_tqdm_color()\n",
        "  \n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from os.path import exists as path_exists\n",
        "from subprocess import Popen, PIPE\n",
        "from PIL import Image, ImageFile\n",
        "from os.path import splitext as split_file\n",
        "import glob\n",
        "from pytti.Notebook import get_last_file\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "try:\n",
        "  params\n",
        "except NameError:\n",
        "  raise RuntimeError(\"ERROR: no parameters. Please run parameters (step 2.1).\")\n",
        "\n",
        "if not path_exists(f\"images_out/{params.file_namespace}\"):\n",
        "  if path_exists(f\"/content/drive/MyDrive\"):\n",
        "    raise RuntimeError(f\"ERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "  else:\n",
        "    raise RuntimeError(f\"WARNING: Drive is not mounted.\\nERROR: file_namespace: {params.file_namespace} does not exist.\")\n",
        "\n",
        "#@markdown The first run executed in `file_namespace` is number $0$, the second is number $1$, etc.\n",
        "\n",
        "latest = -1\n",
        "run_number = latest\n",
        "if run_number == -1:\n",
        "  _, i = get_last_file(f'images_out/{params.file_namespace}', \n",
        "                       f'^(?P<pre>{re.escape(params.file_namespace)}\\\\(?)(?P<index>\\\\d*)(?P<post>\\\\)?_1\\\\.png)$')\n",
        "  run_number = i\n",
        "\n",
        "all_frames = []\n",
        "for i in range(run_number+1):\n",
        "  base_name = params.file_namespace if i == 0 else (params.file_namespace+f\"({i})\")\n",
        "  frames = glob.glob(f'images_out/{params.file_namespace}/{base_name}_*.png')\n",
        "  frames.sort(key = lambda s: int(split_file(s)[0].split('_')[-1]))\n",
        "  all_frames.extend(frames)\n",
        "\n",
        "start_frame = 0#@param{type:\"number\"}\n",
        "all_frames = all_frames[start_frame:]\n",
        "\n",
        "fps =  params.frames_per_second#@param{type:\"raw\"}\n",
        "\n",
        "total_frames = len(all_frames)\n",
        "\n",
        "if total_frames == 0:\n",
        "  #THIS IS NOT AN ERROR. This is the code that would\n",
        "  #make an error if something were wrong.\n",
        "  raise RuntimeError(f\"ERROR: no frames to render in images_out/{params.file_namespace}\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for filename in tqdm(all_frames):\n",
        "  frames.append(Image.open(filename))\n",
        "\n",
        "p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '1', '-preset', 'veryslow', f\"videos/{base_name}.mp4\"], stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "  im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "\n",
        "print(\"Encoding video...\")\n",
        "p.wait()\n",
        "print(\"Video complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-qZ8c_-iZ0QM"
      },
      "outputs": [],
      "source": [
        "# Optionally display your video in the notebook\n",
        "\n",
        "from Ipython.display import Video\n",
        "\n",
        "output_video_filename = \"default.mp4\" # you'll probably need to change this after the first run\n",
        "\n",
        "Video(output_video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if_Fdy_OFkjZ"
      },
      "source": [
        "# Batch Setings\n",
        "\n",
        "Get fancy with a for loop or try using hydra's `--multi-run` feature. Improved documentation for lcoal batch jobs forthcoming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appendix \n",
        "\n",
        "## A.1 Parameter Descriptions\n",
        "\n",
        "`scenes:` Descriptions of scenes you want generated, separated by `||`. Each scene can contain multiple prompts, separated by `|`.\n",
        "\n",
        "*Example:* `Winter sunrise | icy landscape || Winter day | snowy skyline || Winter sunset | chilly air || Winter night | clear sky` would go through several winter scenes.\n",
        "\n",
        "**Advanced:** weight prompts with `description:weight`. Higher `weight` values will be prioritized by the optimizer, and negative `weight` values will remove the description from the image. The default weight is $1$. Weights can also be functions of $t$ to change over the course of an animation.\n",
        "\n",
        "*Example scene:* `blue sky:10|martian landscape|red sky:-1` would try to turn the martian sky blue.\n",
        "\n",
        "**Advanced:** stop prompts once the image matches them sufficiently with `description:weight:stop`. `stop` should be between $0$ and $1$ for positive prompts, or between $-1$ and $0$ for negative prompts. Lower `stop` values will have more effect on the image (remember that $-1<-0.5<0$). A prompt with a negative `weight` will often go haywire without a stop. Stops can also be functions of $t$ to change over the course of an animation.\n",
        "\n",
        "*Example scene:* `Feathered dinosaurs|birds:1:0.87|scales:-1:-.9|text:-1:-.9` Would try to make feathered dinosaurs, lightly like birds, without scales or text, but without making 'anti-scales' or 'anti-text.'\n",
        "\n",
        "#**NEW:**\n",
        "\n",
        "**Advanced:** Use `description:weight_mask description` with a text prompt as `mask`. The prompt will only be applied to areas of the image that match `mask description` according to CLIP.\n",
        "\n",
        "*Example scene:* `Khaleesi Daenerys Targaryen | mother of dragons | dragon:3_baby` would only apply the weight `dragon` to parts of the image that match `baby`, thus turning the babies that `mother` tends to make into dragons (hopefully).\n",
        "\n",
        "**Advanced:** Use `description:weight_[mask]` with a URL or path to an image, or a path to a .mp4 video to use as a `mask`. The prompt will only be applied to the masked (white) areas of the mask image. Use `description:weight_[-mask]` to apply the prompt to the black areas instead.\n",
        "\n",
        "*Example scene:* `sunlight:3_[mask.mp4]|midnight:3_[-mask.mp4]` Would apply `sunlight` in the white areas of `mask.mp4`, and `midnight` in the black areas.\n",
        "\n",
        "**Legacy:** Directional weights will still work as before, but they aren't as good as masks.\n",
        "\n",
        "**Advanced:** Use `[path or url]` as a prompt to add a semantic image prompt. This will be read by CLIP and understood as a near perfect text description of the image.\n",
        "\n",
        "*Example scene:* `[artist signature.png]:-1:-.95|[https://i.redd.it/ewpeykozy7e71.png]:3|fractal clouds|hole in the sky`\n",
        "\n",
        "---\n",
        "\n",
        "`scene_prefix:` text prepended to the beginning of each scene.\n",
        "\n",
        "*Example:* `Trending on Arstation|`\n",
        "\n",
        "`scene_suffix:` text appended to the end of each scene.\n",
        "\n",
        "*Example:* ` by James Gurney`\n",
        "\n",
        "`interpolation_steps:` number of steps to spend smoothly transitioning from the last scene at the start of each scene. $200$ is a good default. Set to $0$ to disable.\n",
        "\n",
        "`steps_per_scene:` total number of steps to spend rendering each scene. Should be at least `interpolation_steps`. This will indirectly control the total length of an animation.\n",
        "\n",
        "---\n",
        "#**NEW**: \n",
        "`direct_image_prompts:` paths or urls of images that you want your image to look like in a literal sense, along with `weight_mask` and `stop` values, separated by `|`.\n",
        "\n",
        "Apply masks to direct image prompts with `path or url of image:weight_path or url of mask` For video masks it must be a path to an mp4 file.\n",
        "\n",
        "**Legacy** latent image prompts are no more. They are now rolled into direct image prompts.\n",
        "\n",
        "---\n",
        "\n",
        "`init_image:` path or url of start image. Works well for creating a central focus.\n",
        "\n",
        "\n",
        "`direct_init_weight:` Defaults to $0$. Use the initial image as a direct image prompt. Equivalent to adding `init_image:direct_init_weight` as a `direct_image_prompt`. Supports weights, masks, and stops.\n",
        "\n",
        "`semantic_init_weight:` Defaults to $0$. Defaults to $0$. Use the initial image as a semantic image prompt. Equivalent to adding `[init_image]:direct_init_weight` as a prompt to each scene in `scenes`. Supports weights, masks, and stops. **IMPORTANT** since this is a semantic prompt, you still need to put the mask in `[` `]` to denote it as a path or url, otherwise it will be read as text instead of a file.\n",
        "\n",
        "---\n",
        "\n",
        "`width`, `height:` image size. Set one of these $-1$ to derive it from the aspect ratio of the init image.\n",
        "\n",
        "`pixel_size:` integer image scale factor. Makes the image bigger. Set to $1$ for VQGAN or face VRAM issues.\n",
        "\n",
        "`smoothing_weight:` makes the image smoother. Defaults to $0$ (no smoothing). Can also be negative for that deep fried look.\n",
        "\n",
        "`image_model:` select how your image will be represented.\n",
        "\n",
        "`vqgan_model:` select your VQGAN version (only for `image_model: VQGAN`)\n",
        "\n",
        "`random_initial_palette:` if checked, palettes will start out with random colors. Otherwise they will start out as grayscale. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`palette_size:` number of colors in each palette. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`palettes:` total number of palettes. The image will have `palette_size*palettes` colors total. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`gamma:` relative gamma value. Higher values make the image darker and higher contrast, lower values make the image lighter and lower contrast. (only for `image_model: Limited Palette`). $1$ is a good default.\n",
        "\n",
        "`hdr_weight:` how strongly the optimizer will maintain the `gamma`. Set to $0$ to disable. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`palette_normalization_weight:` how strongly the optimizer will maintain the palettes' presence in the image. Prevents the image from losing palettes. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`show_palette:` check this box to see the palette each time the image is displayed. (only for `image_model: Limited Palette`)\n",
        "\n",
        "`target_pallete:` path or url of an image which the model will use to make the palette it uses.\n",
        "\n",
        "`lock_pallete:` force the model to use the initial palette (most useful from restore, but will force a grayscale image or a wonky palette otherwise).\n",
        "\n",
        "---\n",
        "\n",
        "`animation_mode:` select animation mode or disable animation.\n",
        "\n",
        "`sampling_mode:` how pixels are sampled during animation. `nearest` will keep the image sharp, but may look bad. `bilinear` will smooth the image out, and `bicubic` is untested :)\n",
        "\n",
        "`infill_mode:` select how new pixels should be filled if they come in from the edge.\n",
        "* mirror: reflect image over boundary\n",
        "* wrap: pull pixels from opposite side\n",
        "* black: fill with black \n",
        "* smear: sample closest pixel in image\n",
        "\n",
        "`pre_animation_steps:` number of steps to run before animation starts, to begin with a stable image. $250$ is a good default.\n",
        "\n",
        "`steps_per_frame:` number of steps between each image move. $50$ is a good default.\n",
        "\n",
        "`frames_per_second:` number of frames to render each second. Controls how $t$ is scaled.\n",
        "\n",
        "`direct_stabilization_weight: ` keeps the current frame as a direct image prompt. For `Video Source` this will use the current frame of the video as a direct image prompt. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_mask.mp4`.\n",
        "\n",
        "`semantic_stabilization_weight: ` keeps the current frame as a semantic image prompt. For `Video Source` this will use the current frame of the video as a direct image prompt. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_[mask.mp4]` or `weight_mask phrase`.\n",
        "\n",
        "`depth_stabilization_weight: ` keeps the depth model output somewhat consistent at a *VERY* steep performance cost. For `Video Source` this will use the current frame of the video as a semantic image prompt. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_mask.mp4`.\n",
        "\n",
        "`edge_stabilization_weight: ` keeps the images contours somewhat consistent at very little performance cost. For `Video Source` this will use the current frame of the video as a direct image prompt with a sobel filter. For `2D` and `3D` this will use the shifted version of the previous frame. Also supports masks: `weight_mask.mp4`.\n",
        "\n",
        "`flow_stabilization_weight: ` used for `animation_mode: 3D` and `Video Source` to prevent flickering. Comes with a slight performance cost for `Video Source`, and a great one for `3D`, due to implementation differences. Also supports masks: `weight_mask.mp4`. For video source, the mask should select the part of the frame you want to move, and the rest will be treated as a still background.\n",
        "\n",
        "---\n",
        "`video_path: ` path to mp4 file for `Video Source`\n",
        "\n",
        "`frame_stride` advance this many frames in the video for each output frame. This is surprisingly useful. Set to $1$ to render each frame. Video masks will also step at this rate.\n",
        "\n",
        "`reencode_each_frame: ` check this box to use each video frame as an `init_image` instead of warping each output frame into the init for the next. Cuts will still be detected and trigger a reencode.\n",
        "\n",
        "\n",
        "`flow_long_term_samples: ` Sample multiple frames into the past for consistent interpolation even with disocclusion, as described by [Manuel Ruder, Alexey Dosovitskiy, and Thomas Brox (2016)](https://arxiv.org/abs/1604.08610). Each sample is twice as far back in the past as the last, so the earliest sampled frame is $2^{\\text{long_term_flow_samples}}$ frames in the past. Set to $0$ to disable.\n",
        "\n",
        "---\n",
        "\n",
        "`translate_x:` horizontal image motion as a function of time $t$ in seconds.\n",
        "\n",
        "`translate_y:` vertical image motion as a function of time $t$ in seconds.\n",
        "\n",
        "`translate_z_3d:` forward image motion as a function of time $t$ in seconds. (only for `animation_mode:3D`)\n",
        "\n",
        "`rotate_3d:` image rotation as a quaternion $\\left[r,x,y,z\\right]$ as a function of time $t$ in seconds. (only for `animation_mode:3D`)\n",
        "\n",
        "`rotate_2d:` image rotation in degrees as a function of time $t$ in seconds. (only for `animation_mode:2D`)\n",
        "\n",
        "`zoom_x_2d:` horizontal image zoom as a function of time $t$ in seconds. (only for `animation_mode:2D`)\n",
        "\n",
        "`zoom_y_2d:` vertical image zoom as a function of time $t$ in seconds. (only for `animation_mode:2D`)\n",
        "\n",
        "`lock_camera:` check this box to prevent all scrolling or drifting. Makes for more stable 3D rotations. (only for `animation_mode:3D`)\n",
        "\n",
        "`field_of_view:` vertical field of view in degrees. (only for `animation_mode:3D`)\n",
        "\n",
        "`near_plane:` closest depth distance in pixels. (only for `animation_mode:3D`)\n",
        "\n",
        "`far_plane:` farthest depth distance in pixels. (only for `animation_mode:3D`)\n",
        "\n",
        "---\n",
        "\n",
        "`file_namespace:` output directory name.\n",
        "\n",
        "`allow_overwrite:` check to overwrite existing files in `file_namespace`.\n",
        "\n",
        "`display_every:` how many steps between each time the image is displayed in the notebook.\n",
        "\n",
        "`clear_every:` how many steps between each time notebook console is cleared.\n",
        "\n",
        "`display_scale:` image display scale in notebook. $1$ will show the image at full size. Does not affect saved images.\n",
        "\n",
        "`save_every:` how many steps between each time the image is saved. Set to `steps_per_frame` for consistent animation.\n",
        "\n",
        "`backups:` number of backups to keep (only the oldest backups are deleted). Large images make very large backups, so be warned. Set to `all` to save all backups. These are used for the `flow_long_term_samples` so be sure that this is at least $2^{\\text{flow_long_term_samples}}+1$ for `Video Source` mode.\n",
        "\n",
        "`show_graphs:` check this to see graphs of the loss values each time the image is displayed. Disable this for local runtimes.\n",
        "\n",
        "`approximate_vram_usage:` currently broken. Don't believe its lies.\n",
        "\n",
        "---\n",
        "\n",
        "`ViTB32, ViTB16, RN50, RN50x4:` select your CLIP models. These take a lot of VRAM.\n",
        "\n",
        "`learning_rate:` how quickly the image changes.\n",
        "\n",
        "`reset_lr_each_frame:` the optimizer will adaptively change the learning rate, so this will thwart it.\n",
        "\n",
        "`seed:` pseudorandom seed.\n",
        "\n",
        "---\n",
        "\n",
        "`cutouts:` number of cutouts. Reduce this to use less VRAM at the cost of quality and speed.\n",
        "\n",
        "`cut_pow:` should be positive. Large values shrink cutouts, making the image more detailed, small values expand the cutouts, making it more coherent. $1$ is a good default. $3$ or higher can cause crashes.\n",
        "\n",
        "`cutout_border:` should be between $0$ and $1$. Allows cutouts to poke out over the edges of the image by this fraction of the image size, allowing better detail around the edges of the image. Set to $0$ to disable. $0.25$ is a good default.\n",
        "\n",
        "`border_mode:` how to fill cutouts that stick out over the edge of the image. Match with `infill_mode` for consistent infill.\n",
        "\n",
        "* clamp: move cutouts back onto image\n",
        "* mirror: reflect image over boundary\n",
        "* wrap: pull pixels from opposite side\n",
        "* black: fill with black \n",
        "* smear: sample closest pixel in image\n",
        "\n",
        "## A.2 Additional Resources\n",
        "\n",
        "Forthcoming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A.3 Debugging tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    torch.cuda.is_available()\n",
        "except ImportError as e:\n",
        "    warnings.warn(\"Please install pytorch with CUDA (GPU): https://pytorch.org/get-started/locally/\")\n",
        "    warnings.warn(\"This is probably what you want: \")\n",
        "\n",
        "try:\n",
        "    import PIL\n",
        "except ImportError as e:\n",
        "    warnings.warn(\"Please install the Python Image Library: conda install -c conda-forge pillow\")\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "except ImportError as e:\n",
        "    warnings.warn(\"Please install OpenCV: conda install -c conda-forge opencv\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "except ImportError as e:\n",
        "    warnings.warn(\"Please install Tensorflow with CUDA (GPU): conda install tensorflow-gpu\")\n",
        "\n",
        "try:\n",
        "    import transformers\n",
        "except:\n",
        "    warnings.warn(\"Please install huggingface/transformers: conda install -c huggingface transformers\")\n",
        "\n",
        "\n",
        "#conda install -c conda-forge imageio\n",
        "#conda install scikit-learn\n",
        "#pip install gdown einops\n",
        "#conda install pytorch-lightning -c conda-forge\n",
        "#conda install -c conda-forge kornia\n",
        "#conda install pandas \n",
        "#conda install seaborn\n",
        "#pip install PyGLM\n",
        "#pip install ftfy regex tqdm hydra-core adjustText exrex bunch matplotlib-label-lines\n",
        "#git clone https://github.com/pytti-tools/pytti-core\n",
        "#pip install ./AdaBins\n",
        "#pip install ./GMA\n",
        "#pip install ./CLIP\n",
        "#pip install ./pytti-core"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pytti 5 beta.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
